{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "Prof. S. Harmeling, SS 2024\n",
    "\n",
    "### Exercise sheet #8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Implement the $n$-step return and $\\lambda$-return.\n",
    "\n",
    "In this notebook, we will implement offline versions for the $n$-step return and $\\lambda$-return.  \n",
    "*Offline* means that the episodes are already generated and we update the value function by iterating over them.  \n",
    "In this case, we can apply the forward view for the $\\lambda$-return and don't need eligibility traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the file `rl_tests.py` is in the same folder as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import rl_tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $n$-step return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture the $n$-step return was defined as:\n",
    "$$\n",
    "g_{t:t+n} = r_{t+1} + \\gamma r_{t+2} + \\ldots + \\gamma^{n-1} r_{t+n} + \\gamma^n V(s_{t+n})\n",
    "$$\n",
    "\n",
    "In the implementation we need to check for episode ends.  \n",
    "To include episode ends, we can write the $n$-step return as:\n",
    "$$\n",
    "g_{t:t+n} = \\begin{cases}\n",
    "    \\sum_{k=0}^{n-1} \\gamma^k \\, r_{t+k+1} + \\gamma^n V(s_{t+n}) & \\text{ if } t + n < T \\\\[5pt]\n",
    "    \\sum_{k=0}^{T-t-1} \\gamma^k \\, r_{t+k+1} & \\text{ if } t + n \\ge T\n",
    "\\end{cases}\n",
    "$$\n",
    "where $T$ is the last time step of the episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_return(v, episode, t, gamma, n):\n",
    "    states = episode['states']\n",
    "    rewards = episode['rewards']\n",
    "    T = len(states) - 1\n",
    "\n",
    "    g = 0.0  # n-step return\n",
    "\n",
    "    #######################################################################\n",
    "    # TODO: Calculate the n-step return for the time step t as described  #\n",
    "    # above.                                                              #\n",
    "    #######################################################################\n",
    "    \n",
    "    #######################################################################\n",
    "    # End of your code.                                                   #\n",
    "    #######################################################################\n",
    "\n",
    "    return g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following code cell to test your implementation.  \n",
    "**Important**: After changing your code, execute the above code cell before running the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_n_step_return():\n",
    "    episode = {\n",
    "        'states': [10, 11, 12, 13, 14, 15, 16, 17],\n",
    "        'rewards': [0.1, 0.2, -0.3, -0.4, 0.2, 0.6, -0.3, -0.2]\n",
    "    }\n",
    "\n",
    "    expected_gs = [\n",
    "        [0.7225, 0.27, 0.2175],\n",
    "        [0.11129375, 0.1006625, 0.97453125],\n",
    "        [-0.164973909375, -0.3841830625, -0.08861375]\n",
    "    ]\n",
    "\n",
    "    for i, n in enumerate([1, 3, 10]):\n",
    "        yield f'n = {n}'\n",
    "        for t, expected_g in enumerate(expected_gs[i]):\n",
    "            v = np.linspace(0.0, 1.0, 21)\n",
    "            g = n_step_return(v, episode, t, 0.95, n)\n",
    "            yield np.isclose(g, expected_g), f'The return is incorrect (error = {abs(expected_g - g):.5f})'\n",
    "            yield None\n",
    "\n",
    "rl_tests.run_tests(test_n_step_return())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\lambda$-return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture the $\\lambda$-return was defined as:\n",
    "$$\n",
    "g^\\lambda_t = (1 - \\lambda) \\sum_{n=1}^{T-t-1} \\lambda^{n-1} g_{t:t+n} + \\lambda^{T-t-1} g_t\n",
    "$$\n",
    "where $T$ is the last time step of the episode.  \n",
    "When we plug in the definitions of $g_{t:t+n}$ and $g_t$, we obtain:\n",
    "$$\n",
    "g^\\lambda_t = (1 - \\lambda) \\sum_{n=1}^{T-t-1} \\lambda^{n-1} \\left( \\sum_{k=0}^{n-1} \\gamma^k \\, r_{t+k+1} + \\gamma^n V(s_{t+n}) \\right) + \\lambda^{T-t-1} \\sum_{k=0}^{T-t-1} \\gamma^k \\, r_{t+k+1}\n",
    "$$\n",
    "\n",
    "For the implementation, we can improve the performance by not recomputing the sum of rewards at every time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_return(v, episode, t, gamma, lmbda):\n",
    "    states = episode['states']\n",
    "    rewards = episode['rewards']\n",
    "    T = len(states) - 1\n",
    "\n",
    "    g = 0.0  # lambda-return\n",
    "\n",
    "    #######################################################################\n",
    "    # TODO: Calculate the lambda-return for time step t as described      #\n",
    "    # above. Try to reuse the sum of rewards, so that you only need one   #\n",
    "    # for-loop.                                                           #\n",
    "    #######################################################################\n",
    "    \n",
    "    #######################################################################\n",
    "    # End of your code.                                                   #\n",
    "    #######################################################################\n",
    "\n",
    "    return g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following code cell to test your implementation.  \n",
    "**Important**: After changing your code, execute the above code cell before running the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lambda_return():\n",
    "    episode = {\n",
    "        'states': [10, 11, 12, 13, 14, 15, 16, 17],\n",
    "        'rewards': [0.1, 0.2, -0.3, -0.4, 0.2, 0.6, -0.3, -0.2]\n",
    "    }\n",
    "\n",
    "    expected_gs = [\n",
    "        [0.7225, 0.27, 0.2175],\n",
    "        [0.5389225074707031, 0.16352106835937502, 0.375833828125],\n",
    "        [0.14202026575970308, -0.12892366577812503, 0.133422613125]\n",
    "    ]\n",
    "\n",
    "    for i, lmbda in enumerate([0.0, 0.5, 0.9]):\n",
    "        yield f'lambda = {lmbda}'\n",
    "        for t, expected_g in enumerate(expected_gs[i]):\n",
    "            v = np.linspace(0.0, 1.0, 21)\n",
    "            g = lambda_return(v, episode, t, 0.95, lmbda)\n",
    "            yield np.isclose(g, expected_g), f'The return is incorrect (error = {abs(expected_g - g):.5f})'\n",
    "            yield None\n",
    "\n",
    "rl_tests.run_tests(test_lambda_return())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "If all tests passed, you can run the following code cells to recreate Figure 12.3 from lecture 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_19():\n",
    "    # Generate an episode for the 19-state random walk environment\n",
    "\n",
    "    state = 10\n",
    "\n",
    "    states = [state]\n",
    "    rewards = [0.0]  # start with 0.0 for correct time steps\n",
    "\n",
    "    terminated = False\n",
    "    while not terminated:\n",
    "        state += 1 if random.random() > 0.5 else -1\n",
    "        if state == 20:\n",
    "            reward = 1.0\n",
    "            terminated = True\n",
    "        elif state == 0:\n",
    "            reward = -1.0\n",
    "            terminated = True\n",
    "        else:\n",
    "            reward = 0\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "\n",
    "    episode = {\n",
    "        'states': states,\n",
    "        'rewards': rewards,\n",
    "        'terminated': terminated,\n",
    "        'truncated': False\n",
    "    }\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the true values to compute the RMSE\n",
    "v_true = np.linspace(-1.0, 1.0, 21)\n",
    "v_true[[0, -1]] = 0\n",
    "print(v_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random walks\n",
    "num_runs = 10\n",
    "num_episodes = 10\n",
    "episodes = []\n",
    "for _ in range(num_runs):\n",
    "    run_episodes = []\n",
    "    for _ in range(num_episodes):\n",
    "        episode = random_walk_19()\n",
    "        run_episodes.append(episode)\n",
    "    episodes.append(run_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(return_fn, episodes, alpha, **params):\n",
    "    avg_rmse = 0.0\n",
    "    for run_episodes in episodes:\n",
    "        run_rmse = 0.0\n",
    "        v = np.zeros(21)\n",
    "        for episode in run_episodes:\n",
    "            states = episode['states']\n",
    "            T = len(states) - 1\n",
    "\n",
    "            for t in range(T):\n",
    "                s = states[t]\n",
    "                g = return_fn(v, episode, t, **params)\n",
    "                v[s] += alpha * (g - v[s])\n",
    "\n",
    "            run_rmse += np.sqrt(np.mean((v - v_true) ** 2))\n",
    "        run_rmse /= len(episodes)\n",
    "        avg_rmse += run_rmse\n",
    "    avg_rmse /= num_runs\n",
    "    return avg_rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate $n$-step returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.0\n",
    "\n",
    "alphas = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "ns = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "n_scores = np.zeros((len(ns), len(alphas)))\n",
    "\n",
    "for i, n in enumerate(ns):\n",
    "    for j, alpha in enumerate(alphas):\n",
    "        n_scores[i, j] = evaluate(n_step_return, episodes, alpha=alpha, gamma=gamma, n=n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate $\\lambda$-returns (may take some time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.0\n",
    "\n",
    "alphas = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "lambdas = [0.0, 0.4, 0.8, 0.9, 0.95, 0.975, 0.99, 1.0]\n",
    "\n",
    "lambda_scores = np.zeros((len(lambdas), len(alphas)))\n",
    "\n",
    "for i, lmbda in enumerate(lambdas):\n",
    "    for j, alpha in enumerate(alphas):\n",
    "        lambda_scores[i, j] = evaluate(lambda_return, episodes, alpha=alpha, gamma=gamma, lmbda=lmbda)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(10, 4))\n",
    "\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_ylim([0.25, 0.55])\n",
    "axes[0].set_xlabel('alpha')\n",
    "axes[0].set_xticks(alphas)\n",
    "for i, n in enumerate(ns):\n",
    "    axes[0].plot(alphas, n_scores[i], label=f'n={n}')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_ylim([0.25, 0.55])\n",
    "axes[1].set_xlabel('alpha')\n",
    "axes[1].set_xticks(alphas)\n",
    "for i, lmbda in enumerate(lambdas):\n",
    "    axes[1].plot(alphas, lambda_scores[i], label=f'lambda={lmbda}')\n",
    "axes[1].legend()\n",
    "\n",
    "fig.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
